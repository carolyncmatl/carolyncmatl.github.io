<html>
<header>
</header>
<body>
<div class="mx-auto" style="width: 820px;">
  <div class="row content">
    <div class="col-12">
    <iframe width="100%" height="465px" 
src="https://www.youtube.com/embed/Qr0B09iQEcM">
</iframe>
<p style="padding-top: 20px"></p>
	<a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-140.pdf">
      Haptic Perception of Liquids Enclosed in Containers
      </a>
      <p style="padding-top: 20px">
		  Service robots will require several important manipulation skills, including the ability to accurately measure and pour liquids. Prior work on robotic liquid pouring has primarily focused on visual techniques for sensing liquids, but these techniques fall short when liquids are obscured by opaque or closed containers. This paper proposes a complementary method for liquid perception via haptic sensing. The robot moves a container through a series of tilting motions and observes the wrenches induced at the manipulator’s wrist by the liquid’s shifting center of mass. That data is then analyzed with a physics-based model to estimate the liquid’s mass and volume. In experiments, this method achieves error margins of less than 1g and 2mL for an unknown liquid in a 600mL cylindrical container. The model can also predict the viscosity of fluids, which can be used for classifying water, oil, and honey with an accuracy of 98%. The estimated volume is used to precisely pour 100mL of water with less than 4% average error.
      </p>
      <p style="padding-top: 20px">
      	@inproceedings{matl2019haptic,
  title={Haptic Perception of Liquids Enclosed in Containers},
  author={<b>Matl, Carolyn </b> and Matthew, Robert and Bajcsy, Ruzena},
  booktitle={2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={7142--7149},
  year={2019},
  organization={IEEE}
}
      </p>
    </div>
  </div>
</div>
</body>
</html>